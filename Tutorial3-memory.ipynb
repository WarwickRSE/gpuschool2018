{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to GPU Programming Summer School\n",
    "========================\n",
    "\n",
    "D. Quigley, University of Warwick\n",
    "\n",
    "---\n",
    "\n",
    "# Tutorial 3: Memory\n",
    "\n",
    "Blurb to follow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import what we'll need for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                 # Numpy\n",
    "from numba import cuda, float64    # Cuda and numba float64 datatype\n",
    "\n",
    "import matplotlib.pyplot as plt    # Matplotlib\n",
    "%matplotlib inline                 \n",
    "\n",
    "from timeit import default_timer as timer  # Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following kernel. This evolves a point on a 2D grid forward in time according to a simple finite-difference scheme for numerically solving the diffusion equation.\n",
    "\n",
    "$$ U^{n+1}_{i,j} = U^{n}_{i,j} + D \\delta t\\left[\\frac{ U^{n}_{i-1,j} - 2 U^{n}_{i,j} + U^{n}_{i+1,j} }{{\\delta x}^2} + \\frac{ U^{n}_{i,j-1} - 2 U^{n}_{i,j} + U^{n}_{i,j+1} }{{\\delta y}^2} \\right] $$\n",
    "\n",
    "Here $U$ is some function which obeys the diffusion equation, and $D$ is the diffusion coefficient. Grid spacings are  $\\delta x$ and $\\delta y$ and time is evolved forward in steps of $\\delta t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def diffusion_kernel(D, invdx2, invdy2, dt, d_u, d_u_new):\n",
    "    \"\"\"\n",
    "    Simple kernel to evolve a function U forward in time according to an explicit FTCS\n",
    "    finite difference scheme. Arguments are...\n",
    "    \n",
    "    D       : Diffusion coefficient\n",
    "    invdx2  : 1/(dx^2) where dx is the grid spacing in the x direction \n",
    "    invdy2  : 1/(dy^2) where dy is the grid spacing in the y direction\n",
    "    dt      : time step\n",
    "    d_u     : Device array storing U at the current time step\n",
    "    d_u_new : Device array storing U at the next time step\n",
    "    \"\"\"\n",
    "    \n",
    "    # Which row and column on the simulation grid should this thread use\n",
    "    row = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n",
    "    col = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    \n",
    "    # Check that the inex\n",
    "    if row < d_u.shape[0] and col < d_u.shape[1]:\n",
    "    \n",
    "        # Neighbour cells using period boundary conditions\n",
    "        up   = (row + 1)%d_u.shape[0]\n",
    "        down = (row - 1)%d_u.shape[0]\n",
    "    \n",
    "        left  = (col - 1)%d_u.shape[1]\n",
    "        right = (col + 1)%d_u.shape[1]\n",
    "        \n",
    "        # Compute second derivatives of u w.r.t. x and y\n",
    "        d2udx2 = (d_u[row,left]  - 2.0*d_u[row,col] + d_u[row,right])*invdx2\n",
    "        d2udy2 = (d_u[down,col]  - 2.0*d_u[row,col] + d_u[up,col])*invdy2\n",
    "    \n",
    "        # Populate u_new with the time-evolved function\n",
    "        d_u_new[row, col] = d_u[row, col] + D * dt * ( d2udx2 + d2udy2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need some parameters/data to play with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAFpCAYAAABu98hvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAD1tJREFUeJzt3VuopXd5x/HfY2Iqth5Kg2Ay0UQ6KQ6hEBtSS6Eq2pLkIrmxkoBYS3DQNvbCUkixeIhXtbSCkFYHKlZBY/RCB4mk1EYUMTYDajSRlGkUM0QaqzE3QWPo04u1KtudPbPfmexD8vj5wIZ1+O+1n/zd+5vXdx1S3R0Ant6esd8DAPDkiTnAAGIOMICYAwwg5gADiDnAANvGvKo+VFUPVdW3TnJ/VdX7q+p4Vd1dVS/b+TEBOJUlR+YfTnLFKe6/MsnB9dfhJP/05McC4HRsG/Pu/mKSH51iyTVJPtIrdyZ5flW9cKcGBGB7O3HO/PwkD2y4fmJ9GwB75OwdeIza4rYtPyOgqg5ndSomyTN/Jzl3B348wBQ/TvejWzV1WzsR8xNJLthw/UCSB7da2N1HkhxJkqrz+uddByDrPJ6RnTjNcjTJG9avanl5kke6+/s78LgALLTtkXlVfTzJK5OcW1UnkrwzyTOTpLs/kOS2JFclOZ7k0SR/ulvDArC1bWPe3ddtc38n+fMdmwiA0+YdoAADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwwg5gADiDnAAGIOMICYAwywKOZVdUVV3VdVx6vqxi3uf1FV3VFVX6uqu6vqqp0fFYCT2TbmVXVWkpuTXJnkUJLrqurQpmV/k+TW7r40ybVJ/nGnBwXg5JYcmV+e5Hh339/djyW5Jck1m9Z0kueuLz8vyYM7NyIA2zl7wZrzkzyw4fqJJL+7ac27kvxrVb01ya8mec2OTAfAIkuOzGuL23rT9euSfLi7DyS5KslHq+oJj11Vh6vqWFUdSx49/WkB2NKSmJ9IcsGG6wfyxNMo1ye5NUm6+ytJnpXk3M0P1N1Huvuy7r4sefaZTQzAEyyJ+V1JDlbVRVV1TlZPcB7dtOZ7SV6dJFX10qxi/oOdHBSAk9s25t39eJIbktye5NtZvWrlnqq6qaquXi/7yyRvqqpvJPl4kjd29+ZTMQDsktqv5lad18nhffnZAE9NR9L94FbPU27LO0ABBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGCAJf9xCp7C3pl37/cIkCR5d9653yP8UnNkDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjDAophX1RVVdV9VHa+qG0+y5nVVdW9V3VNVH9vZMQE4lbO3W1BVZyW5OckfJjmR5K6qOtrd925YczDJXyf5/e5+uKpesFsDA/BES47ML09yvLvv7+7HktyS5JpNa96U5ObufjhJuvuhnR0TgFNZEvPzkzyw4fqJ9W0bXZzk4qr6clXdWVVXbPVAVXW4qo5V1bHk0TObGIAn2PY0S5La4rbe4nEOJnllkgNJvlRVl3T3j3/hm7qPJDmSJFXnbX4MAM7QkiPzE0ku2HD9QJIHt1jzme7+WXd/J8l9WcUdgD2wJOZ3JTlYVRdV1TlJrk1ydNOaTyd5VZJU1blZnXa5fycHBeDkto15dz+e5IYktyf5dpJbu/ueqrqpqq5eL7s9yQ+r6t4kdyT5q+7+4W4NDcAvWnLOPN19W5LbNt32jg2XO8nb1l8A7DHvAAUYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGCARTGvqiuq6r6qOl5VN55i3Wurqqvqsp0bEYDtbBvzqjoryc1JrkxyKMl1VXVoi3XPSfIXSb6600MCcGpLjswvT3K8u+/v7seS3JLkmi3WvSfJe5P8ZAfnA2CBJTE/P8kDG66fWN/2c1V1aZILuvuzp3qgqjpcVceq6ljy6GkPC8DWzl6wpra4rX9+Z9UzkrwvyRu3e6DuPpLkyOr7zuttlgOw0JIj8xNJLthw/UCSBzdcf06SS5J8oaq+m+TlSY56EhRg7yyJ+V1JDlbVRVV1TpJrkxz9/zu7+5HuPre7L+zuC5PcmeTq7j62KxMD8ATbxry7H09yQ5Lbk3w7ya3dfU9V3VRVV+/2gABsb8k583T3bUlu23TbO06y9pVPfiwATod3gAIMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABiDjCAmAMMIOYAA4g5wABn7/cAPDnvzjv3ewTgKcCROcAAYg4wgJgDDCDmAAOIOcAAYg4wgJgDDCDmAAOIOcAAYg4wgJgDDCDmAAMsinlVXVFV91XV8aq6cYv731ZV91bV3VX1+ap68c6PCsDJbBvzqjoryc1JrkxyKMl1VXVo07KvJbmsu387yaeSvHenBwXg5JYcmV+e5Hh339/djyW5Jck1Gxd09x3d/ej66p1JDuzsmACcypKYn5/kgQ3XT6xvO5nrk3zuyQwFwOlZ8h+nqC1u6y0XVr0+yWVJXnGS+w8nOby69rxFAwKwvSUxP5Hkgg3XDyR5cPOiqnpNkrcneUV3/3SrB+ruI0mOrNaft+W/EAA4fUtOs9yV5GBVXVRV5yS5NsnRjQuq6tIkH0xydXc/tPNjAnAq28a8ux9PckOS25N8O8mt3X1PVd1UVVevl/1dkl9L8smq+npVHT3JwwGwC6p7f852rE6zHN6Xnw3w1HQk3Q9u9TzltrwDFGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAHEHGAAMQcYQMwBBhBzgAEWxbyqrqiq+6rqeFXduMX9v1JVn1jf/9WqunCnBwXg5LaNeVWdleTmJFcmOZTkuqo6tGnZ9Uke7u7fTPK+JH+704MCcHJLjswvT3K8u+/v7seS3JLkmk1rrknyL+vLn0ry6qqqnRsTgFNZEvPzkzyw4fqJ9W1brunux5M8kuQ3dmJAALZ39oI1Wx1h9xmsSVUdTnJ4ffWnybu/teDnT3Zukv/Z7yGeAuyDPUjsQZL81pl+45KYn0hywYbrB5I8eJI1J6rq7CTPS/KjzQ/U3UeSHEmSqjrW3ZedydBT2IMV+2APEnuQrPbgTL93yWmWu5IcrKqLquqcJNcmObppzdEkf7K+/Nok/97dTzgyB2B3bHtk3t2PV9UNSW5PclaSD3X3PVV1U5Jj3X00yT8n+WhVHc/qiPza3RwagF+05DRLuvu2JLdtuu0dGy7/JMkfn+bPPnKa6yeyByv2wR4k9iB5EntQzoYAPP15Oz/AALsecx8FsGgP3lZV91bV3VX1+ap68X7MuZu224MN615bVV1V417VsGQPqup169+Fe6rqY3s9415Y8Pfwoqq6o6q+tv6buGo/5twtVfWhqnqoqrZ8aXatvH+9P3dX1csWPXB379pXVk+Y/leSlyQ5J8k3khzatObPknxgffnaJJ/YzZn2+mvhHrwqybPXl9/yy7gH63XPSfLFJHcmuWy/596H34ODSb6W5NfX11+w33Pv0z4cSfKW9eVDSb6733Pv8B78QZKXJfnWSe6/Ksnnsnr/zsuTfHXJ4+72kbmPAliwB919R3c/ur56Z1av5Z9kye9BkrwnyXuT/GQvh9sjS/bgTUlu7u6Hk6S7H9rjGffCkn3oJM9dX35envi+lqe17v5itngfzgbXJPlIr9yZ5PlV9cLtHne3Y+6jAJbtwUbXZ/Vv5Um23YOqujTJBd392b0cbA8t+T24OMnFVfXlqrqzqq7Ys+n2zpJ9eFeS11fViaxeRffWvRntKeN0m5Fk4UsTn4Qd+yiAp7HF/3xV9foklyV5xa5OtPdOuQdV9YysPm3zjXs10D5Y8ntwdlanWl6Z1f87+1JVXdLdP97l2fbSkn24LsmHu/vvq+r3snoPyyXd/b+7P95Twhk1cbePzE/nowByqo8CeBpbsgepqtckeXuSq7v7p3s0217Zbg+ek+SSJF+oqu9mdZ7w6LAnQZf+LXymu3/W3d9Jcl9WcZ9kyT5cn+TWJOnuryR5Vlaf2/LLYlEzNtvtmPsogAV7sD7F8MGsQj7xPOkp96C7H+nuc7v7wu6+MKvnDa7u7jP+nIqnoCV/C5/O6snwVNW5WZ12uX9Pp9x9S/bhe0lenSRV9dKsYv6DPZ1yfx1N8ob1q1penuSR7v7+tt+1B8/cXpXkP7N6Bvvt69tuyuqPNVn9D/XJJMeT/EeSl+z3s837sAf/luS/k3x9/XV0v2fe6z3YtPYLGfZqloW/B5XkH5Lcm+SbSa7d75n3aR8OJflyVq90+XqSP9rvmXf4n//jSb6f5GdZHYVfn+TNSd684ffg5vX+fHPp34J3gAIM4B2gAAOIOcAAYg4wgJgDDCDmAAOIOcAAYg4wgJgDDPB/ixuPrnEgqr4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65799d7dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an empty array\n",
    "dim = 1920\n",
    "c = np.zeros((dim, dim))\n",
    "\n",
    "# Fill the middle of the grid with a concentration of 1.0\n",
    "for irow in range(c.shape[0] // 4, 3*c.shape[0] // 4):\n",
    "    for icol in range(c.shape[1] // 4, 3*c.shape[1] // 4):\n",
    "        c[irow, icol] = 1.0\n",
    "        \n",
    "# We want this to represent a square domain spanning 0 -> 1 in each direction\n",
    "domain = [0.0, 1.0, 0.0, 1.0]\n",
    "                                        \n",
    "D = 1.0  # Diffusion coefficient\n",
    "\n",
    "x_spacing = 1.0/float(c.shape[0])\n",
    "y_spacing = 1.0/float(c.shape[1])\n",
    "\n",
    "# Store spacing as inverse square to avoid repeated division\n",
    "inv_xspsq = 1.0/(x_spacing**2)\n",
    "inv_yspsq = 1.0/(y_spacing**2)\n",
    "\n",
    "# Satisfy stability condition \n",
    "time_step = 0.25*min(x_spacing,y_spacing)**2\n",
    "                \n",
    "# Plot \n",
    "fig = plt.figure(figsize = [6, 6])\n",
    "plt.imshow(c,cmap='jet',extent=domain);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now got everything we need to use `diffusion_kernel` to evolve this initial condition forward in time on the GPU. Let's time this and examine the output. Note that I've been careful here to ensure that the grid size is an exact multiple of the number of threads in a block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy this array to the device, and create a new device array to hold updated value\n",
    "d_c = cuda.to_device(c)\n",
    "d_c_new = cuda.device_array(c.shape, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation took 5043.265406 milliseconds using simple kernel\n"
     ]
    }
   ],
   "source": [
    "threads_per_block = (32, 32)\n",
    "blocks_per_grid   = (dim//32, dim//32)\n",
    "\n",
    "start = timer()  # Start timer\n",
    "\n",
    "# Evolve forward 2000 steps\n",
    "for step in range(2000):\n",
    "\n",
    "    # Launch the kernel    \n",
    "    diffusion_kernel[blocks_per_grid,threads_per_block](D, inv_xspsq, inv_yspsq, time_step, d_c, d_c_new)\n",
    "\n",
    "    # Swap the identit of the old and new device arrays\n",
    "    d_c, d_c_new = d_c_new, d_c\n",
    "       \n",
    "elapsed_time = (timer() - start)*1000.0\n",
    "print(\"Simulation took %f milliseconds using simple kernel\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6579abd0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Copy the current concentration from the device to the host\n",
    "c = d_c.copy_to_host()\n",
    "\n",
    "# Display the current concentration profile\n",
    "fig = plt.figure(figsize = [6, 6])\n",
    "plt.imshow(c,cmap='jet',extent=[0.0, 1.0, 0.0, 1.0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of this kernel is okay, but we can do better.\n",
    "\n",
    "Consider the part of the kernel which reads from the device array d_u.\n",
    "\n",
    "```python\n",
    "        # Compute second derivatives of u w.r.t. x and y\n",
    "        d2udx2 = (d_u[row,left]  - 2.0*d_u[row,col] + d_u[row,right])*invdx2\n",
    "        d2udy2 = (d_u[down,col]  - 2.0*d_u[row,col] + d_u[up,col])*invdy2\n",
    "    \n",
    "        # Populate u_new with the time-evolved function\n",
    "        d_u_new[row, col] = d_u[row, col] + D * dt * ( d2udx2 + d2udy2) \n",
    "```\n",
    "Each instance of the kernel (i.e. each thread) needs to load five entries from the array ```d_u``` in device global memory.  Loads from memory are slow compared to compute operations, so there's a good chance these loads account for a significant fraction of the time measured.\n",
    "\n",
    "We can improve this by recognising that other threads within the same thread block will also need some of these  five entries. If those threads can *share* the data that is loaded from global memory then we'd cut down on the number of loads needed. This is what shared memory is used for - a local (but limited in size) on-chip cache where we can store data which multiple threads within the block will need.\n",
    "\n",
    "Consider the following kernel. Here threads in blocks of 32 x 32 each load one element from global memory into shared memory. To avoid needing data outside of the shared memory array, only the interior 30 x 30 threads perform computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def diffusion_kernel_shared(D, invdx2, invdy2, dt, d_u, d_u_new):\n",
    "    \"\"\"\n",
    "    Kernel to evolve a function U forward in time according to an explicit FTCS\n",
    "    finite difference scheme. Shared memory is used. Arguments are...\n",
    "    \n",
    "    D       : Diffusion coefficient\n",
    "    invdx2  : 1/(dx^2) where dx is the grid spacing in the x direction \n",
    "    invdy2  : 1/(dy^2) where dy is the grid spacing in the y direction\n",
    "    dt      : time step\n",
    "    d_u     : Device array storing U at the current time step\n",
    "    d_u_new : Device array storing U at the next time step\n",
    "    \"\"\"\n",
    "    \n",
    "    # Shared array large enough to store 30x30 block + \"halo\" of boundary neighbours\n",
    "    # N.B. the size of the shared array is set at compile time, but see also \n",
    "    # https://stackoverflow.com/questions/30510580/numba-cuda-shared-memory-size-at-runtime\n",
    "    u_sh = cuda.shared.array((32, 32), dtype=float64)\n",
    "    \n",
    "    # Row and column in global matrix - 32 x 32 grid including halo\n",
    "    row = cuda.threadIdx.y + cuda.blockIdx.y * ( cuda.blockDim.y - 2 ) - 1\n",
    "    col = cuda.threadIdx.x + cuda.blockIdx.x * ( cuda.blockDim.x - 2 ) - 1\n",
    "    \n",
    "    # Row and column in shared memory tile\n",
    "    sh_row = cuda.threadIdx.y\n",
    "    sh_col = cuda.threadIdx.x\n",
    "    \n",
    "    # Apply periodic boundary conditions\n",
    "    row = row%d_u.shape[0]\n",
    "    col = col%d_u.shape[1]\n",
    "    \n",
    "    # Copy from device memory to shared memory\n",
    "    u_sh[sh_row, sh_col] = d_u[row, col]\n",
    "    \n",
    "    # Do not proceed until all threads reach this point\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    # Only threads which belong to the interior 30 x 30 grid compute\n",
    "    # (The other 32^2 - 30^30 = 124 threads do nothing)\n",
    "    if sh_row > 0 and sh_row < 31 and sh_col > 0 and sh_col < 31:\n",
    "        \n",
    "        left  = sh_col - 1\n",
    "        right = sh_col + 1\n",
    "        \n",
    "        up   = sh_row + 1\n",
    "        down = sh_row - 1 \n",
    "        \n",
    "        d2udx2 = (u_sh[sh_row, left]  - 2.0*u_sh[sh_row, sh_col] + u_sh[sh_row, right])*invdx2\n",
    "        d2udy2 = (u_sh[down, sh_col]  - 2.0*u_sh[sh_row, sh_col] + u_sh[up, sh_col])*invdy2\n",
    "    \n",
    "        d_u_new[row, col] = u_sh[sh_row, sh_col] + D * dt * ( d2udx2 + d2udy2)  \n",
    "    \n",
    "    u_sh = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each thread now only performs one load from global memory, but we'll need to launch more blocks to cover the grid.\n",
    "\n",
    "Let's see if this works. Reset to the initial condition..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array\n",
    "dim = 1920\n",
    "c = np.zeros((dim, dim))\n",
    "\n",
    "# Fill the middle of the grid with a concentration of 1.0\n",
    "for irow in range(c.shape[0] // 4, 3*c.shape[0] // 4):\n",
    "    for icol in range(c.shape[1] // 4, 3*c.shape[1] // 4):\n",
    "        c[irow, icol] = 1.0\n",
    "        \n",
    "d_c = cuda.to_device(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and launch the new kernel, being careful to use more blocks than before to cover the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation took 3766.357676 milliseconds using kernel with shared memory\n"
     ]
    }
   ],
   "source": [
    "threads_per_block = (32, 32)\n",
    "blocks_per_grid   = (dim//30, dim//30)\n",
    "\n",
    "start = timer()\n",
    "\n",
    "# Evolve forward 2000 steps\n",
    "for step in range(2000):\n",
    "\n",
    "    # Launch the kernel    \n",
    "    diffusion_kernel_shared[blocks_per_grid,threads_per_block](D, inv_xspsq, inv_yspsq, time_step, d_c, d_c_new)\n",
    " \n",
    "    # Swap the identit of the old and new device arrays\n",
    "    d_c, d_c_new = d_c_new, d_c\n",
    "    \n",
    "t = (timer() - start)*1000.0\n",
    "\n",
    "elapsed_time = (timer() - start)*1000.0\n",
    "print(\"Simulation took %f milliseconds using kernel with shared memory\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6571527470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Copy the current concentration from the device to the host\n",
    "c = d_c.copy_to_host()\n",
    "\n",
    "# Display the current concentration profile\n",
    "fig = plt.figure(figsize = [6, 6])\n",
    "plt.imshow(c,cmap='jet',extent=[0.0, 1.0, 0.0, 1.0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When testing this resulted in a saving of approximately 25%, despite the fact that we're not using all of the threads in a block to do computation. The saving on loads from global memory has more than offset that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "* How do these kernels perform relative to the corresponding CPU implementation? Use the Tinis GPU node to gather your benchmarks and remember to take averages excluding compilation.\n",
    "\n",
    "* How does the benefit gained from using shared memory to eliminate redundant loads vary with the size of the grid and the number of timesteps simulated?\n",
    "\n",
    "* (Advanced) How does the balance between use of shared memory and threads idle during computation change when moving from 2D to 3D?\n",
    "\n",
    "* (Very advanced) Can you create a kernel for this problem which exploits the use of shared memory without leaving any threads idle during computation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atomic operations\n",
    "\n",
    "Shared memory can also be used if wanting multiple threads to read/write to the same variable without going to global memory. This raises the issue of contention and possible race conditions.\n",
    "\n",
    "Consider the following which sums over the elements in each row of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def sum_row(d_a, d_sum):\n",
    "    \"\"\"Given a device array a, calculate the sum over elements in each row.\"\"\"\n",
    "\n",
    "    # Get row and column of current element\n",
    "    row = cuda.threadIdx.y    + cuda.blockIdx.y * cuda.blockDim.y\n",
    "    column = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    \n",
    "    if (row < d_a.shape[0]):\n",
    "        if column == 0 :                   \n",
    "            d_sum[row] = 0.0 # First thread in row initialises sum\n",
    "    \n",
    "    if (row < d_a.shape[0]):\n",
    "        if column < d_a.shape[1]:\n",
    "            #cuda.atomic.add(d_sum, row , d_a[row, column])\n",
    "            d_sum[row] += d_a[row, column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this on a trivial array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4109009 ,  0.32985664],\n",
       "       [ 0.7324165 ,  0.03337033],\n",
       "       [ 0.09103772,  0.27676996]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random 3 x 2 array\n",
    "my_array = np.random.rand(3, 2)\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.74075754,  0.76578683,  0.36780768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate sum over elements in each row (axis = 1 means sum over columns)\n",
    "np.sum(my_array, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same calculation using our new kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32985664,  0.03337033,  0.27676996])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy data to device and create new array for output\n",
    "d_my_array = cuda.to_device(my_array)\n",
    "d_my_sum   = cuda.device_array(3, dtype=np.float64)\n",
    "\n",
    "# Launch a single thread block of 2 x 3 threads\n",
    "sum_row[(1, 1), (2, 3)](d_my_array, d_my_sum)\n",
    "\n",
    "# Copy result back and print it\n",
    "my_sum = d_my_sum.copy_to_host()\n",
    "my_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panic - this hasn't given us the correct result. What could be wrong? \n",
    "\n",
    "The problem is a *race condition*. There is nothing stopping threads in columns other than column 0 from adding in their contribution to the sum before it has been initialised. \n",
    "\n",
    "Similarly if a thread A must the current value of the sum before adding its own contribution. If another thread B changes the sum after A has read the old value, but before A writes the result of its sum, A will be working with a *stale* value and get the wrong result.\n",
    "\n",
    "We can take steps to fix this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def sum_row_v2(d_a, d_sum):\n",
    "    \"\"\"Given a device array a, calculate the sum over elements in each row.\"\"\"\n",
    "\n",
    "    # Get row and column of current element\n",
    "    row = cuda.threadIdx.y    + cuda.blockIdx.y * cuda.blockDim.y\n",
    "    column = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    \n",
    "    if (row < d_a.shape[0]):\n",
    "        if column == 0 :                   \n",
    "            d_sum[row] = 0.0 # First thread in row initialises sum\n",
    "    \n",
    "    # No thread can pass this point until all threads reach this statement\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    if (row < d_a.shape[0]):\n",
    "        if column < d_a.shape[1]:\n",
    "            \n",
    "            # Add to element 'row' of array d_sum\n",
    "            cuda.atomic.add(d_sum, row , d_a[row, column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've used an *atomic operation* - in this case the operation 'sum'. Atomics prevent more than one thread at a time being able to read/write from a particular memory location. They act like a thread lock. Other operations than sum are available. See [the documentation](https://numba.pydata.org/numba-doc/dev/cuda/intrinsics.html).\n",
    "\n",
    "We've also use ```cuda.syncthreads()``` to ensure no thread writes to the sum before it it initialised.\n",
    "\n",
    "Let's check that we get the correct answer this time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.74075754,  0.76578683,  0.36780768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy data to device and create new array for output\n",
    "d_my_array = cuda.to_device(my_array)\n",
    "d_my_sum   = cuda.device_array(3, dtype=np.float64)\n",
    "\n",
    "# Launch a single thread block of 2 x 3 threads\n",
    "sum_row_v2[(1, 1), (2, 3)](d_my_array, d_my_sum)\n",
    "\n",
    "# Copy result back and print it\n",
    "my_sum = d_my_sum.copy_to_host()\n",
    "my_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew. Be aware that use of atomics slows code down drastically. They effectively serialise the operations they perform. \n",
    "\n",
    "We can also use atomics on shared memory if we want to reduce access to global memory, but we need to be aware that shared memory only persists for the lifetime of the thread block and so any result must be written back to global memory once computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def sum_row_v3(d_a, d_sum):\n",
    "    \"\"\"Given a device array a, calculate the sum over elements in each row.\"\"\"\n",
    "\n",
    "    # Get row and column of current element\n",
    "    row = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n",
    "    column = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    \n",
    "    # Create shared memory array to use for summation\n",
    "    sum_sh = cuda.shared.array(3, dtype=float64)\n",
    "    \n",
    "    if (row < d_a.shape[0]):\n",
    "        if column == 0 :                   \n",
    "            sum_sh[row] = 0.0 # First thread in row initialises sum\n",
    "\n",
    "    cuda.syncthreads()\n",
    "    \n",
    "    if (row < d_a.shape[0]):\n",
    "        if column < d_a.shape[1]:\n",
    "            \n",
    "            # Add to element 'row' of array sum_sh. Note that we \n",
    "            # don't need to read from global memory anymore\n",
    "            cuda.atomic.add(sum_sh, row , d_a[row, column])\n",
    "            \n",
    "    cuda.syncthreads()\n",
    "           \n",
    "    # Write result to global memory\n",
    "    if (row < d_a.shape[0]):        \n",
    "        if column == 0 : d_sum[row] = sum_sh[row]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that this still works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.74075754,  0.76578683,  0.36780768])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy data to device and create new array for output\n",
    "d_my_array = cuda.to_device(my_array)\n",
    "d_my_sum   = cuda.device_array(3, dtype=np.float64)\n",
    "\n",
    "# Launch a single thread block of 2 x 3 threads\n",
    "sum_row_v3[(1, 1), (2, 3)](d_my_array, d_my_sum)\n",
    "\n",
    "# Copy result back and print it\n",
    "my_sum = d_my_sum.copy_to_host()\n",
    "my_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "* The kernel used in ```sum_row_v3``` above will only work as advertised if the array we want to sum over fits within a single thread block. Create a new kernel which will work for arrays of any size and test your result against the sum method of a numpy array on the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Constant memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our final example we'll do something a bit more substantial for which we might expect to see a significant benefit from using a GPU. Imagine we have a function of three variables $f(x,y,z)$ which is defined as a sum over Gaussians centered on $P$ different points $\\{x_{i},y_{i},z_{i}\\}$. We are only interested in the function between -10 and +10 in each direction.\n",
    "\n",
    "$$f(x,y,z) = \\sum_{i=1}^{P}A\\exp\\left\\{-w\\left[\\left(x-x_{i}\\right)^2+\\left(y-y_{i}\\right)^2+\\left(z-z_{i}\\right)^2\\right]\\right\\}$$\n",
    "\n",
    "Our goal is to integrate out (numerically) one of the dimensions and obtain a two-dimensional function\n",
    "\n",
    "$$g(x,y) = \\int_{-10}^{10}\\exp\\left[f(x,y,z)\\right] dz.$$\n",
    "\n",
    "To compute this function on a $N_{grid} \\times N_{grid}$ mesh in the $x,y$ plane, we must perform the above integration over $z$ at each point. For simplicity we will integrate numerically over $N_{grid}$ points in the $z$ direction using the trapezoidal rule. We must therefore evaluate the function a total of $N_{grid}^3 $ times which quickly becomes expensive as the size of the grid increases.\n",
    "\n",
    "Exactly this problem can arise in molecular simulation when attempting to create a two-dimensional probability density plot from a reconstructed free energy. For anyone intersted, $f(x,y,z)$ is a free energy reconstructed from the points $\\{x_{i},y_{i},z_{i}\\}$ visited during a molecular dynamics simulation. $x,y$ and $z$ are themselves functions of atomic coordinates, such as the end-to-end distance of a polymer, or the number of hydrogen bonds in a system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "/*================================================\n",
    "  This program uses the data and functions above \n",
    "  module above to compute the two-dimensional \n",
    "  function g(x,y). Note that we store the function \n",
    "  in a long vector of length Ngrid*Ngrid rather \n",
    "  than in a 2D matrix.\n",
    "!===============================================*/\n",
    "int main () {\n",
    "\n",
    "  // Extend of domain in each dimension\n",
    "  float gridMax =  10.0f;\n",
    "  float gridMin = -10.0f;\n",
    "\n",
    "  // Number of grid points in each dimension\n",
    "  int Ngrid = 128;\n",
    "\n",
    "  // Array to hold set of P points on the host\n",
    "  float *tmpPoints;\n",
    "\n",
    "  // Memory for g on the host\n",
    "  float *g_host;\n",
    "\n",
    "  // Memory for g on the device\n",
    "  float *g_dev;\n",
    "\n",
    "  // Variables to hold the dimensions of the block\n",
    "  // and thread grids. The dim3 type is provided in cuda.h\n",
    "  int blocksPerGrid,threadsPerBlock;\n",
    "  dim3 blocks,threads;\n",
    "\n",
    "  // cudaError_t is a type defined in cuda.h\n",
    "  cudaError_t err;\n",
    "\n",
    "  int i,j,igrid,jgrid,count,idev;\n",
    "  float x;\n",
    "\n",
    "  // Make sure we have a CUDA capable device to work with\n",
    "  err = cudaGetDeviceCount(&count);\n",
    "  if ( (count==0) || (err!=cudaSuccess) ) {\n",
    "    printf(\"No CUDA supported devices are available in this system.\\n\");\n",
    "    exit(EXIT_FAILURE);\n",
    "  } else {\n",
    "    printf(\"Found %d CUDA devices in this system\\n\",count);\n",
    "  }\n",
    "\n",
    "  err = cudaGetDevice(&idev);\n",
    "  if ( err!=cudaSuccess ) {\n",
    "    printf(\"Error identifying active device\\n\");\n",
    "    exit(EXIT_FAILURE);\n",
    "  }\n",
    "  printf(\"Using device %d\\n\",idev);\n",
    "\n",
    "  // Allocate memory for points on the host\n",
    "  tmpPoints = (float *)malloc(3*P*sizeof(float));\n",
    "\n",
    "  // Populate tmpPoints with random numbers between -10 and 10\n",
    "  for (i=0;i<P;i++) {\n",
    "    for (j=0;j<3;j++) {\n",
    "      x = rand()/(float)RAND_MAX;\n",
    "      tmpPoints[3*i+j] = gridMin + (gridMax-gridMin)*x;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Copy from tmpPoints on the host to points on the device\n",
    "  err = cudaMemcpyToSymbol(points,tmpPoints,3*P*sizeof(float));\n",
    "  if ( err!=cudaSuccess ) {\n",
    "    printf(\"Error copying points to device\\n\");\n",
    "    exit(EXIT_FAILURE);\n",
    "  }\n",
    "\n",
    "  printf(\"Copied array of points to device memory\\n\");\n",
    "\n",
    "  // Release memory on the host\n",
    "  free(tmpPoints);\n",
    "\n",
    "  // Allocate memory for g on the device and zero it out\n",
    "  err = cudaMalloc(&g_dev,Ngrid*Ngrid*sizeof(float));\n",
    "  if ( err!=cudaSuccess ) {\n",
    "    printf(\"Error allocating memory for g_dev on device\\n\");\n",
    "    exit(EXIT_FAILURE);\n",
    "  }\n",
    "  cudaMemset(g_dev,0,Ngrid*Ngrid*sizeof(float));\n",
    "\n",
    "  // Allocate memory for g on the host and zero it out\n",
    "  g_host = (float *)malloc(Ngrid*Ngrid*sizeof(float));\n",
    "  memset(g_host,0,Ngrid*Ngrid*sizeof(float));\n",
    "\n",
    "  // We want a thread running the integrate1D kernel for every\n",
    "  // point in g_dev that we want to evaluate. \n",
    "  // Pick a sensible block size\n",
    "  blocksPerGrid   = 10;\n",
    " \n",
    "  // Calculate the number of threads per block to make up the\n",
    "  // entire grid of Ngrid*Ngrid threads\n",
    "  threadsPerBlock = Ngrid/blocksPerGrid;\n",
    "  if (Ngrid%blocksPerGrid!=0) { threadsPerBlock += 1; }\n",
    "\n",
    "  // Multidimensional grid dimensions, use the dim3 type\n",
    "  blocks.x  = blocksPerGrid   ; blocks.y  = blocksPerGrid   ; blocks.z  = 1;\n",
    "  threads.x = threadsPerBlock ; threads.y = threadsPerBlock ; threads.z = 1;\n",
    "\n",
    "  // Launch our kernel to compute g_dev on the device\n",
    "  printf(\"Using block grid dimensions of %d by %d\\n\",blocks.x,blocks.y);\n",
    "  printf(\"Thread grid within a block is  %d by %d\\n\",threads.x,threads.y);\n",
    "\n",
    "  clock_t t1 = clock();\n",
    "\n",
    "  printf(\"Launching %d threads\\n\",blocks.x*blocks.y*threads.x*threads.y);\n",
    "\n",
    "  integrate1D<<<blocks,threads>>>(gridMin,gridMax,Ngrid,g_dev);\n",
    "  cudaThreadSynchronize();\n",
    "\n",
    "  clock_t t2 = clock();\n",
    "\n",
    "  // Copy from the device to the host\n",
    "  err = cudaMemcpy(g_host,g_dev,Ngrid*Ngrid*sizeof(float),cudaMemcpyDeviceToHost);\n",
    "  if ( err != cudaSuccess ) {\n",
    "    printf(\"Error copying g from device to host\\n\");\n",
    "    exit(EXIT_FAILURE);\n",
    "  }\n",
    "\n",
    "  printf(\"Time taken on GPU = %f seconds\\n\",(double)(t2-t1)/(double)CLOCKS_PER_SEC);\n",
    "\n",
    "  // print some sample points\n",
    "  for (i=0;i<2;i++) {\n",
    "    for (j=0;j<2;j++) {\n",
    "      igrid = (i+1)*Ngrid/2-1;\n",
    "      jgrid = (j+1)*Ngrid/2-1;\n",
    "      printf(\"g(%d,%d) = %f\\n\",igrid,jgrid,g_host[igrid*Ngrid+jgrid]);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Release device memory\n",
    "  cudaFree(g_dev);\n",
    "  cudaFree(points);\n",
    "\n",
    "  // Release host memory\n",
    "  free(g_host);\n",
    "\n",
    "  return 0;\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
