{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to GPU Programming Summer School\n",
    "========================\n",
    "\n",
    "D. Quigley, University of Warwick\n",
    "\n",
    "---\n",
    "\n",
    "## Pros?\n",
    "\n",
    "* #### Parallel execution of threads on thousands of compute units (cores) within a small and (relatively) inexpensive device\n",
    "* #### Huge energy efficiency in comparison to the same performance on a traditional CPU cluster\n",
    "\n",
    "## Cons?\n",
    "\n",
    "* ####  Typically no more than 32GB of RAM per device, compared to 2-4GB per CPU core in traditional HPC clusters\n",
    "* ####  Clock rate of around 1 GHz vs 3-4 GHz in CPUs, and less work done per clock 'tick'\n",
    "* ####  Bandwidth between device memory and the compute units is fast, but not thousands of times faster than CPUs\n",
    "* ####  Threads are grouped into *warps* which all execute instructions in lockstep\n",
    "* ####  Code must be (re)written to explicitly make use of the GPU capabilities\n",
    "* ####  Only a (growing) subset of your favourite langauge features can execute on a GPU\n",
    "* ####  Not all computational tasks are suitable for GPU acceleration\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements for GPU computing\n",
    "\n",
    "* #### [A CUDA-capable Nvidia GPU](https://www.geforce.com/hardware/technology/cuda/supported-gpus)\n",
    "* #### [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit)\n",
    "* #### Cheap (£60) desktop cards fine for development and testing, but performance very limited\n",
    "* #### High-end gaming cards (£600-£1,000) can be very powerful for CUDA but lack error/detection and features needed for remote monitoring and management in server environments\n",
    "* #### Tesla series aimed squarely at high performance computing market\n",
    "\n",
    "\n",
    "| GPU card              |  Cores  | Single Precision TFLOPS | Double Precision TFLOPS   | GPU Memory Bandwidth Gb/s  |\n",
    "| ----------------------|:--------|:------------------------|:-------------------------:|---------------------------:|\n",
    "| Tesla K20 (2012)        | 2496 | 3.52 | 1.18 |  208 |\n",
    "| Tesla K40 ([Chiron](https://warwick.ac.uk/research/rtp/sc/hpc)) (2014)         | 2880 | 4.23 | 1.43 |  235 |\n",
    "| Telsa K80 ([Tinis](https://warwick.ac.uk/research/rtp/sc/hpc)) (2015)   |  4992   | 5.59 | 1.87                      | 480                        |\n",
    "| Tesla P100 ([Orac](https://warwick.ac.uk/research/rtp/sc/hpc)) (2017)   |  3584   | 8.07 | 4.36                       | 732                        |\n",
    "| GeForce 1080Ti (Gaming)|  3584   | 10.6 | 0.36                     | 484                        |\n",
    "\n",
    "(Quoting [Wikipedia](https://en.wikipedia.org/wiki/Nvidia_Tesla) - TFLOPS shown are without Nvidia Boost)\n",
    "\n",
    "---\n",
    "\n",
    "## Programming model\n",
    "\n",
    "* ####  CUDA is the (proprietary) programming model for exploiting Nvidia GPUs\n",
    "* ####  Others exist (e.g. OpenCL) but arguably CUDA has become the de-facto standard and is much easier to learn\n",
    "* ####  CUDA extends the C programming language with GPU features. CUDA Fortran also exists (not free but the SC RTP has a license for it)\n",
    "* ####  Various third party tools for other languages - we will focus on [Numba](https://numba.pydata.org/) for Python as it appears closer in spirit to CUDA with compiled languages and so concepts are transferable\n",
    "\n",
    "---\n",
    "    \n",
    "![Nvidia K20c GPU](http://product-images.www8-hp.com/digmedialib/prodimg/lowres/c03730717.png)\n",
    "\n",
    "---\n",
    "\n",
    "## CUDA and the [Scientific Computing Research Technology Platform (SCRTP)](https://warwick.ac.uk/research/rtp/sc)\n",
    "\n",
    "* #### New desktop (2018) release supports CUDA toolkit 9.1 for machines with GPU cards capable of running Nvidia 390 series driver or newer\n",
    "* #### Check support using `nvidia-smi` in the terminal\n",
    "* #### About 2/3 of the machines are supported. Some spare GeForce 1030 cards will be available for machines which can accomodate them\n",
    "\n",
    "\n",
    "## This course\n",
    "\n",
    "* #### As hands-on as possible\n",
    "* #### Using the SCRTP (managed workstation + Tinis)\n",
    "* #### I will demonstrate codes snippets via Jupyter notebooks which you can download and tinker with as we go\n",
    "* #### I am not showing you high quality code here - no exception handling etc\n",
    "* #### Reserved 1 x GPU node on Tinis with 4 x GPUs for excercises\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check of Python environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All being well, you've reading this text inside a Jupyter notebook environment running on an SCRTP machine equipped with a CUDA-compatible GPU card and have launched the notebook from within an environment configured to support GPU computing. If in doubt, check the [connecting instructions](https://warwick.ac.uk/fac/sci/maths/research/events/2017-18/nonsymposium/gpu/connecting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run some simple checks to make sure you can execute code on a GPU from within this notebook. For today we'll be working with the Python interface to CUDA provided via the numba package.\n",
    "\n",
    "Some terminology we need aleady:\n",
    "\n",
    "**Host**        : The traditional computer in which our code is running on a CPU with access to host RAM.\n",
    "\n",
    "**CUDA Device** : The GPU card consisting of its own RAM and computing cores (lots of them). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform          # So we can figure out where we're running\n",
    "from numba import cuda   # Import python interface to CUDA\n",
    "\n",
    "# Report where we're running\n",
    "print(\"========================================================\")\n",
    "print(\"This notebook is running on \", platform.node())\n",
    "print(\"========================================================\")\n",
    "\n",
    "# Test if CUDA is available. If so report on the devices present \n",
    "if cuda.is_available():  \n",
    "    \n",
    "    # List of CUDA capable devices in this system\n",
    "    for device in cuda.list_devices():       \n",
    "        print(\"Device ID : \", device.id, \" : \", device.name.decode())         \n",
    "    \n",
    "else:\n",
    "    print(\"There doesn't appear to be a CUDA capable device in this system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select the the most appropriate device and query its [compute capability](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities). CUDA devices have varying compute capability depending on the product range and when they were manufactured. Typically CUDA software will be written to support a minimum compute capability.\n",
    "\n",
    "[Numba requires a compute capability of 2.0 or higher](https://numba.pydata.org/numba-doc/dev/cuda/overview.html), so we should check this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_instance = cuda.select_device(0) # Create a device instance to work with based on device 0 \n",
    "\n",
    "# The compute capability is stored as a tuple (major, minor) so we're good to go if...\n",
    "if my_instance.compute_capability[0] >= 2:\n",
    "    print(\"The selected device (\",my_instance.name.decode(),\") has a sufficient compute capability\")\n",
    "else:\n",
    "    print(\"The selected device does not have a sufficient compute capability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally we won't need to call ```cuda.select_device()```. The default context will be the fastest GPU in the machine. I'm only using this here to interrogate compute cabability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
